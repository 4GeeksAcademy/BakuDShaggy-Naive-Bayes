{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Step 1: Load and Explore Data\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>package_name</th>\n",
                            "      <th>review</th>\n",
                            "      <th>polarity</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>privacy at least put some option appear offli...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>messenger issues ever since the last update, ...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>profile any time my wife or anybody has more ...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>the new features suck for those of us who don...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>forced reload on uploading pic on replying co...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "          package_name                                             review  \\\n",
                            "0  com.facebook.katana   privacy at least put some option appear offli...   \n",
                            "1  com.facebook.katana   messenger issues ever since the last update, ...   \n",
                            "2  com.facebook.katana   profile any time my wife or anybody has more ...   \n",
                            "3  com.facebook.katana   the new features suck for those of us who don...   \n",
                            "4  com.facebook.katana   forced reload on uploading pic on replying co...   \n",
                            "\n",
                            "   polarity  \n",
                            "0         0  \n",
                            "1         0  \n",
                            "2         0  \n",
                            "3         0  \n",
                            "4         0  "
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Your code here\n",
                "import pandas as pd\n",
                "import pickle\n",
                "import seaborn as sns\n",
                "from wordcloud import WordCloud\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
                "from sklearn.metrics import accuracy_score\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "import matplotlib.pyplot as plt\n",
                "# Load data\n",
                "url = \"https://raw.githubusercontent.com/4GeeksAcademy/naive-bayes-project-tutorial/main/playstore_reviews.csv\"\n",
                "df = pd.read_csv(url)\n",
                "\n",
                "# Show first 5 rows\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Step 2: Preprocess Text Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "🔍 Package Name Analysis:\n"
                    ]
                },
                {
                    "ename": "KeyError",
                    "evalue": "'package_name'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[31mKeyError\u001b[39m: 'package_name'",
                        "\nThe above exception was the direct cause of the following exception:\n",
                        "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# --- 1. Package Analysis ---\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🔍 Package Name Analysis:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnique apps: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpackage_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.nunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTop 5 apps by review count:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Top apps analysis \u001b[39;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
                        "\u001b[31mKeyError\u001b[39m: 'package_name'"
                    ]
                }
            ],
            "source": [
                "# Remove irrelevant column\n",
                "df = df.drop(columns=['package_name'])\n",
                "\n",
                "# Clean text: lowercase + remove extra spaces\n",
                "df['review'] = df['review'].str.strip().str.lower()\n",
                "\n",
                "# --- 1. Package Analysis ---\n",
                "print(\"\\n🔍 Package Name Analysis:\")\n",
                "print(f\"Unique apps: {df['package_name'].nunique()}\")\n",
                "print(f\"Top 5 apps by review count:\")\n",
                "\n",
                "# Top apps analysis \n",
                "plt.figure(figsize=(12, 8))\n",
                "top_apps = df['package_name'].value_counts().nlargest(5)\n",
                "ax = sns.barplot(x=top_apps.values, y=top_apps.index, palette='viridis')\n",
                "plt.title('Top 5 Most Reviewed Apps', fontsize=16)\n",
                "plt.xlabel('Number of Reviews')\n",
                "plt.ylabel('Application')\n",
                "\n",
                "# Add sentiment distribution\n",
                "for i, app in enumerate(top_apps.index):\n",
                "    app_reviews = df[df['package_name']==app]\n",
                "    pos_percent = 100 * app_reviews['polarity'].mean()\n",
                "    ax.text(top_apps.values[i] + 20, i, \n",
                "            f'{pos_percent:.1f}% positive', \n",
                "            va='center', fontsize=10)\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# --- 2. Remove package column ---\n",
                "df = df.drop(columns=['package_name'])\n",
                "print(\"✅ Dropped 'package_name' column as instructed\")\n",
                "\n",
                "# --- 3. Sentiment Distribution ---\n",
                "plt.figure(figsize=(10, 6))\n",
                "ax = sns.countplot(x='polarity', data=df, palette='viridis', hue='polarity', legend=False)\n",
                "plt.title('Sentiment Distribution (0=Negative, 1=Positive)', fontsize=16)\n",
                "plt.xlabel('Sentiment')\n",
                "plt.ylabel('Count')\n",
                "\n",
                "# Add percentages\n",
                "total = len(df)\n",
                "for p in ax.patches:\n",
                "    percentage = f'{100 * p.get_height()/total:.1f}%'\n",
                "    x = p.get_x() + p.get_width()/2\n",
                "    y = p.get_height() + 50\n",
                "    ax.annotate(percentage, (x, y), ha='center', fontsize=10)\n",
                "plt.show()\n",
                "\n",
                "# --- 4. Review Length Analysis ---\n",
                "df['review_length'] = df['review'].apply(len)\n",
                "df['word_count'] = df['review'].apply(lambda x: len(x.split()))\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
                "sns.histplot(df, x='review_length', hue='polarity', bins=30, \n",
                "             kde=True, palette='viridis', ax=axes[0])\n",
                "axes[0].set_title('Character Length Distribution', fontsize=14)\n",
                "axes[0].set_xlabel('Number of Characters')\n",
                "\n",
                "sns.histplot(df, x='word_count', hue='polarity', bins=30, \n",
                "             kde=True, palette='viridis', ax=axes[1])\n",
                "axes[1].set_title('Word Count Distribution', fontsize=14)\n",
                "axes[1].set_xlabel('Number of Words')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# --- 5. Word Clouds ---\n",
                "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
                "positive_text = \" \".join(df[df['polarity']==1]['review'])\n",
                "negative_text = \" \".join(df[df['polarity']==0]['review'])\n",
                "\n",
                "positive_wc = WordCloud(width=600, height=400, background_color='white', \n",
                "                        colormap='viridis', max_words=100).generate(positive_text)\n",
                "axes[0].imshow(positive_wc)\n",
                "axes[0].set_title('Positive Reviews - Top 100 Words', fontsize=16)\n",
                "axes[0].axis('off')\n",
                "\n",
                "negative_wc = WordCloud(width=600, height=400, background_color='white', \n",
                "                        colormap='plasma', max_words=100).generate(negative_text)\n",
                "axes[1].imshow(negative_wc)\n",
                "axes[1].set_title('Negative Reviews - Top 100 Words', fontsize=16)\n",
                "axes[1].axis('off')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# --- 6. Sentiment vs Length ---\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.boxplot(x='polarity', y='review_length', data=df, palette='viridis')\n",
                "plt.title('Review Length vs. Sentiment', fontsize=16)\n",
                "plt.xlabel('Sentiment (0=Negative, 1=Positive)')\n",
                "plt.ylabel('Character Count')\n",
                "plt.show()\n",
                "\n",
                "# Correlation calculation\n",
                "corr = df[['polarity', 'review_length']].corr().iloc[0,1]\n",
                "print(f\"\\n📊 Correlation between sentiment and review length: {corr:.4f} (near zero = no relationship)\")\n",
                "\n",
                "# --- 7. Cleanup before modeling ---\n",
                "df = df.drop(columns=['review_length', 'word_count'])\n",
                "print(\"✅ Temporary columns dropped\")\n",
                "\n",
                "\n",
                "# Drop temporary columns before modeling\n",
                "df = df.drop(columns=['review_length', 'word_count'])\n",
                "# Split data\n",
                "X = df['review']\n",
                "y = df['polarity']\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Step 3: Convert Text to Numbers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create word-count matrix (ignore English stopwords like \"the\", \"and\")\n",
                "vectorizer = CountVectorizer(stop_words='english')\n",
                "X_train_vec = vectorizer.fit_transform(X_train).toarray()\n",
                "X_test_vec = vectorizer.transform(X_test).toarray()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Step 4: Build & Compare Naive Bayes Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Accuracy</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>MultinomialNB</th>\n",
                            "      <td>0.815642</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>BernoulliNB</th>\n",
                            "      <td>0.770950</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>GaussianNB</th>\n",
                            "      <td>0.804469</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "               Accuracy\n",
                            "MultinomialNB  0.815642\n",
                            "BernoulliNB    0.770950\n",
                            "GaussianNB     0.804469"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Initialize models\n",
                "models = {\n",
                "    \"MultinomialNB\": MultinomialNB(),\n",
                "    \"BernoulliNB\": BernoulliNB(),\n",
                "    \"GaussianNB\": GaussianNB()\n",
                "}\n",
                "\n",
                "# Train and evaluate\n",
                "results = {}\n",
                "for name, model in models.items():\n",
                "    model.fit(X_train_vec, y_train)\n",
                "    y_pred = model.predict(X_test_vec)\n",
                "    accuracy = accuracy_score(y_test, y_pred)\n",
                "    results[name] = accuracy\n",
                "\n",
                "# Show results\n",
                "pd.DataFrame.from_dict(results, orient='index', columns=['Accuracy'])\n",
                "# --- Model Performance Analysis ---\n",
                "print(\"\\n🔬 Model Performance Insights:\")\n",
                "\n",
                "# 1. Create comparison plot\n",
                "models_df = pd.DataFrame.from_dict(results, orient='index', columns=['Accuracy'])\n",
                "plt.figure(figsize=(10, 6))\n",
                "ax = sns.barplot(x=models_df.index, y=models_df['Accuracy'], palette='viridis')\n",
                "plt.title('Naive Bayes Model Comparison', fontsize=16)\n",
                "plt.ylabel('Accuracy')\n",
                "plt.ylim(0.75, 0.85)  # Focus on relevant range\n",
                "\n",
                "# Add accuracy labels\n",
                "for p in ax.patches:\n",
                "    ax.annotate(f\"{p.get_height():.4f}\", \n",
                "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
                "                ha='center', va='center', \n",
                "                xytext=(0, 10), \n",
                "                textcoords='offset points')\n",
                "plt.show()\n",
                "\n",
                "# 2. Explain why MultinomialNB performed best\n",
                "print(\"Why MultinomialNB won:\")\n",
                "print(\"- Our features are WORD COUNTS (discrete numbers)\")\n",
                "print(\"- MultinomialNB handles discrete frequency data best\")\n",
                "print(\"- BernoulliNB assumes binary features (presence/absence)\")\n",
                "print(\"- GaussianNB assumes continuous normal distributions\")\n",
                "\n",
                "# 3. Show top predictive words\n",
                "feature_names = vectorizer.get_feature_names_out()\n",
                "coefs = models[\"MultinomialNB\"].feature_log_prob_[1] - models[\"MultinomialNB\"].feature_log_prob_[0]\n",
                "top_words = pd.DataFrame({\n",
                "    'Word': feature_names,\n",
                "    'Weight': coefs\n",
                "}).sort_values('Weight', key=abs, ascending=False).head(10)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.barplot(x='Weight', y='Word', data=top_words, palette='viridis')\n",
                "plt.title('Top 10 Predictive Words', fontsize=16)\n",
                "plt.xlabel('Sentiment Weight (Positive vs Negative)')\n",
                "plt.show()\n",
                "\n",
                "print(\"💡 Interpretation:\")\n",
                "print(\"Positive weights → Strongly associated with POSITIVE reviews\")\n",
                "print(\"Negative weights → Strongly associated with NEGATIVE reviews\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Step 5: Optimize the Best Model\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Alpha 0.1: Accuracy = 0.8324\n",
                        "Alpha 0.5: Accuracy = 0.8268\n",
                        "Alpha 1.0: Accuracy = 0.8156\n",
                        "Alpha 2.0: Accuracy = 0.8324\n"
                    ]
                }
            ],
            "source": [
                "# Tune MultinomialNB (best performer)\n",
                "alphas = [0.1, 0.5, 1.0, 2.0]  # Smoothing parameters\n",
                "\n",
                "for alpha in alphas:\n",
                "    model = MultinomialNB(alpha=alpha)\n",
                "    model.fit(X_train_vec, y_train)\n",
                "    acc = model.score(X_test_vec, y_test)\n",
                "    print(f\"Alpha {alpha}: Accuracy = {acc:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Step 6: Compare with Random Forest\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Random Forest Accuracy: 0.8045\n",
                        "Best NB Accuracy: 0.8156\n"
                    ]
                }
            ],
            "source": [
                "# Train Random Forest\n",
                "rf = RandomForestClassifier(n_estimators=100)\n",
                "rf.fit(X_train_vec, y_train)\n",
                "rf_acc = rf.score(X_test_vec, y_test)\n",
                "\n",
                "print(f\"Random Forest Accuracy: {rf_acc:.4f}\")\n",
                "print(f\"Best NB Accuracy: {max(results.values()):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Step 7: Save the Model\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save best model\n",
                "best_model = MultinomialNB(alpha=0.5)\n",
                "best_model.fit(X_train_vec, y_train)\n",
                "pickle.dump(best_model, open('naive_bayes_model.pkl', 'wb'))\n",
                "\n",
                "# Save vectorizer too (for new text preprocessing)\n",
                "pickle.dump(vectorizer, open('vectorizer.pkl', 'wb'))\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
